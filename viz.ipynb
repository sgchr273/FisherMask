{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import importlib\n",
    "# ann = importlib.import_module(\"active-nn\")\n",
    "\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "imp_wts = pickle.load(open(\"./Save/Imp_weights/imp_wts_idxs_exper25K_1per.p\", \"rb\"))\n",
    "type(imp_wts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imp_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rd_imp_wts = imp_wts[-1]\n",
    "type(error_rd_imp_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_rd_imp_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet.ResNet18()\n",
    "filename = \"exper25K_1per\"\n",
    "error_rd = 12\n",
    "model.load_state_dict(torch.load(\"./Save/Models/\"+ filename +\"/model_\" +  str(error_rd) + \".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_dataset = pickle.load(open(\"./Save/Queried_idxs/dataset_exper25K_1per.p\", \"rb\"))\n",
    "type(saved_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(saved_dataset.keys())\n",
    "X_tr, Y_tr = saved_dataset['X_train'], saved_dataset['Y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs_lb = pickle.load(open(\"./Save/Queried_idxs/queried_idxs_exper25K_1per.p\", \"rb\"))\n",
    "type(idxs_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rd_idxs_lb = idxs_lb[-1]\n",
    "type(error_rd_idxs_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs_lb_before_error = []\n",
    "for idxs in idxs_lb:\n",
    "    idxs_lb_before_error.extend(idxs)\n",
    "\n",
    "len(idxs_lb_before_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/home/sgchr/anaconda3/envs/pyt/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/home/sgchr/anaconda3/envs/pyt/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import dataset as D \n",
    "import vgg\n",
    "\n",
    "\n",
    "\n",
    "handler = D.get_handler(\"CIFAR10\")\n",
    "args = {'n_epoch': 3, 'transform': transforms.Compose([ \n",
    "                        transforms.RandomCrop(32, padding=4),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "                    ]),\n",
    "                    'loader_tr_args':{'batch_size': 128, 'num_workers': 1},\n",
    "                    'loader_te_args':{'batch_size': 100, 'num_workers': 1}, # change back to 1000\n",
    "                    'optimizer_args':{'lr': 0.05, 'momentum': 0.3},\n",
    "                    'transformTest': transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])}\n",
    "\n",
    "\n",
    "args['fishIdentity'] = 0\n",
    "args['fishInit'] = 1\n",
    "args['lamb'] = 1\n",
    "args['backwardSteps'] = 0\n",
    "args['pct_top'] = 0.01\n",
    "args['savefile'] = \"exper25K_1per\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lp_grads = strategy.log_prob_grads_wrt(error_rd_imp_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imp_per_layer = [len(t) for t in error_rd_imp_wts]\n",
    "log_prob_grads = np.zeros((len(Y_tr), len(np.unique(Y_tr)), sum(num_imp_per_layer))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "masks_list = []\n",
    "for layer_num, layer_wt in enumerate(list(model.parameters())):\n",
    "    mask = np.zeros_like(layer_wt.detach().cpu().numpy(), dtype=bool)\n",
    "    for tup in error_rd_imp_wts[layer_num]:\n",
    "        mask[tup] = True\n",
    "    masks_list.append(mask)\n",
    "\n",
    "model.to('cuda')\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "model.eval()\n",
    "parameters = tuple(model.parameters())\n",
    "    \n",
    "test_loader = DataLoader(handler(X_tr, Y_tr, transform=args['transform']), shuffle=False, **args['loader_te_args']) # 'transformTest'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (1280,) into shape (1285,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/usr/local/home/sgchr/Documents/active_nn/viz.ipynb Cell 16\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Br11ast8hv.managed.mst.edu/usr/local/home/sgchr/Documents/active_nn/viz.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m         grad \u001b[39m=\u001b[39m grad\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()  \u001b[39m# https://discuss.pytorch.org/t/should-it-really-be-necessary-to-do-var-detach-cpu-numpy/35489\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Br11ast8hv.managed.mst.edu/usr/local/home/sgchr/Documents/active_nn/viz.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m         selected_grads \u001b[39m=\u001b[39m grad[masks_list[i]]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Br11ast8hv.managed.mst.edu/usr/local/home/sgchr/Documents/active_nn/viz.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m         log_prob_grads[idxs[n]][c][pos:(pos\u001b[39m+\u001b[39;49m\u001b[39mlen\u001b[39;49m(error_rd_imp_wts[i]))] \u001b[39m=\u001b[39m selected_grads\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Br11ast8hv.managed.mst.edu/usr/local/home/sgchr/Documents/active_nn/viz.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m         pos \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(selected_grads)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Br11ast8hv.managed.mst.edu/usr/local/home/sgchr/Documents/active_nn/viz.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (1280,) into shape (1285,)"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "for test_batch, test_labels, idxs in test_loader:\n",
    "    test_batch, test_labels = test_batch.cuda(), test_labels.cuda()\n",
    "    \n",
    "    outputs, e1 = model(test_batch)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    probs = F.softmax(outputs, dim=1).to('cpu')\n",
    "    log_probs = F.log_softmax(outputs, dim=1)\n",
    "    N, C = log_probs.shape\n",
    "\n",
    "    for n in range(N):\n",
    "\n",
    "        for c in range(C):\n",
    "\n",
    "            grad_list = torch.autograd.grad(log_probs[n][c], parameters, retain_graph=True) # ~0.007 secs\n",
    "\n",
    "            \n",
    "            pos = 0\n",
    "            for i, grad in enumerate(grad_list):    # different layers # ~0.2 secs ~ 0.003 secs per iteration\n",
    "\n",
    "                grad = grad.detach().cpu().numpy()  # https://discuss.pytorch.org/t/should-it-really-be-necessary-to-do-var-detach-cpu-numpy/35489\n",
    "                selected_grads = grad[masks_list[i]]\n",
    "\n",
    "                log_prob_grads[idxs[n]][c][pos:(pos+len(error_rd_imp_wts[i]))] = selected_grads\n",
    "                \n",
    "                pos += len(selected_grads)\n",
    "            \n",
    "        \n",
    "        model.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1285"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_rd_imp_wts[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(masks_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_grads = {i: np.random.uniform(size=p.shape) for i, p in enumerate(parameters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_grads[60] = 1 + sq_grads[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6184818651513364"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_grads[60][3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mask(sq_grads_expect, pct_top=0.02):\n",
    "    list_t = list(sq_grads_expect.values())\n",
    "    combined_arrays = np.hstack([t.flatten() for t in sq_grads_expect.values()]) \n",
    "    list_lengths = [len(ten.flatten()) for ten in list_t]\n",
    "    cum_lengths = np.cumsum(list_lengths)\n",
    "    sorted_idxs = np.argsort(combined_arrays[:cum_lengths[-2]])\n",
    "    num_top = int(pct_top * len(combined_arrays))\n",
    "    # top_idxs = sorted_idxs[-num_top:]\n",
    "\n",
    "    num_last_layer = sum(list_lengths[-1:]) \n",
    "    # in FISH ResNet architecture, the last layer has bias=False\n",
    "    # if last layer has both weight and bias, set -1 to -2 above\n",
    "\n",
    "    if num_last_layer < num_top:\n",
    "        top_idxs = np.hstack(\n",
    "            [sorted_idxs[-(num_top - num_last_layer):], \n",
    "            np.arange(cum_lengths[-2], cum_lengths[-1])]\n",
    "        )\n",
    "        assert len(top_idxs) == num_top\n",
    "    else:\n",
    "        raise ValueError(\"too small top percentage\")\n",
    "\n",
    "    imp_wt_idxs = [[] for i in range(len(list_t))]\n",
    "    for idx in top_idxs:\n",
    "        prev_length = 0\n",
    "        for idx_layer_num, length in enumerate(cum_lengths):\n",
    "            if idx < length and length > prev_length: \n",
    "                # print(len_idx)\n",
    "                try:\n",
    "                    # s_num[len_idx].append(np.where(combined_s[idx] == list_s[len_idx])[0][0])\n",
    "                    idx_tuple = np.nonzero(combined_arrays[idx] == list_t[idx_layer_num])\n",
    "                    '''pass only numpy or python objects to numpy functions'''\n",
    "                    # s_num[len_idx].append([idx[0] for idx in idx_tuple])\n",
    "                    imp_wt_idxs[idx_layer_num].append(idx_tuple)\n",
    "                except Exception:\n",
    "                    print(\"caught error: \", idx, idx_layer_num, length, imp_wt_idxs)\n",
    "                    raise\n",
    "                break\n",
    "            prev_length = length\n",
    "    return imp_wt_idxs\n",
    "\n",
    "test_imp_wts = calculate_mask(sq_grads, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_imp_wts[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 13, 0, 2, 16, 0, 0, 23, 0, 0, 33, 0, 0, 40, 0, 0, 83, 0, 1, 4, 1, 0, 67, 0, 0, 80, 0, 0, 119, 0, 2, 305, 0, 0, 10, 0, 0, 325, 0, 0, 301, 0, 1, 604, 0, 0, 1177, 1, 0, 73, 2, 1, 1204, 2, 1, 1241, 2, 0, 1280]\n"
     ]
    }
   ],
   "source": [
    "print([len(test_imp_wts[i]) for i in range(len(test_imp_wts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(([1,2],[2,3],[2,2]))\n",
    "b = np.array(([2,0],[4,3],[6,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_vhstack_dispatcher() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/usr/local/home/sgchr/Documents/active_nn/viz.ipynb Cell 26\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Br11ast8hv.managed.mst.edu/usr/local/home/sgchr/Documents/active_nn/viz.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m c\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mhstack(a)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Br11ast8hv.managed.mst.edu/usr/local/home/sgchr/Documents/active_nn/viz.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m np\u001b[39m.\u001b[39;49mhstack(a,b)\n",
      "File \u001b[0;32m<__array_function__ internals>:179\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _vhstack_dispatcher() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# c=np.hstack(a)\n",
    "np.hstack(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2560"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1280*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 128)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_grads[60].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
