{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.multiprocessing import Pool, Array\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single GPU memory in R11 computer\n",
    "\n",
    "can fit 500 samples, 40000 imp wts for each, 10 classes, computes trace in 31 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def initpool(arr):\n",
    "#     global sharedArr\n",
    "#     sharedArr = arr\n",
    "\n",
    "# def trace_for_chunk(xt_, rank, chunkSize, num_gpus, currentInv, fisher, gpu_id):\n",
    "#     upper_bound = int(xt_.shape[0]/(num_gpus-gpu_id))\n",
    "#     lower_bound = int(upper_bound-(xt_.shape[0]/num_gpus))\n",
    "#     t = time.time()\n",
    "#     traceEst = np.frombuffer(sharedArr.get_obj(), dtype=np.float64)\n",
    "#     # print(\"Beginning GPU \", gpu_id, \" at time: \", time.time(), flush=True)\n",
    "#     for c_idx in range(lower_bound, upper_bound, chunkSize):\n",
    "#         xt_chunk = xt_[c_idx : c_idx + chunkSize]\n",
    "#         # xt_chunk = torch.tensor(xt_chunk).clone().detach().cuda(gpu_id)\n",
    "#         xt_chunk = xt_chunk.clone().detach().cuda(gpu_id)\n",
    "#         currentInv = currentInv.cuda(gpu_id)\n",
    "#         fisher = fisher.cuda(gpu_id)\n",
    "#         innerInv = torch.inverse(torch.eye(rank).cuda(gpu_id) + xt_chunk @ currentInv @ xt_chunk.transpose(1, 2))\n",
    "#         # print('fisher: ', fisher, '\\n', 'curentinv: ', currentInv, '\\n', 'xt_chunk: ', xt_chunk)\n",
    "#         innerInv[torch.where(torch.isinf(innerInv))] = torch.sign(innerInv[torch.where(torch.isinf(innerInv))]) * np.finfo('float32').max\n",
    "#         traceEst[c_idx : c_idx + chunkSize] = torch.diagonal(\n",
    "#             xt_chunk @ currentInv @ fisher @ currentInv @ xt_chunk.transpose(1, 2) @ innerInv,\n",
    "#             dim1=-2,\n",
    "#             dim2=-1\n",
    "#         ).sum(-1).detach().cpu()\n",
    "#         # print(time.time()-t)\n",
    "#     del xt_chunk, fisher, currentInv\n",
    "#     # print(\"Finishing GPU \", gpu_id, \" at time: \", time.time(), flush=True)\n",
    "#     return\n",
    "\n",
    "from checking_multiproc import initpool, trace_for_chunk\n",
    "\n",
    "dim = 10 * 3000 #X.shape[-1]\n",
    "rank = 10 #X.shape[-2]\n",
    "fisher = torch.rand((dim, dim)).cuda()\n",
    "currentInv = torch.rand((dim, dim)).cuda()\n",
    "xt_ = torch.rand((100, rank, dim)).cuda()\n",
    "\n",
    "## using 2 GPUs\n",
    "chunkSize = 500\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "tE = Array('d', xt_.shape[0], lock=True)\n",
    "\n",
    "with Pool(processes=NUM_GPUS, initializer=initpool, initargs=(tE,)) as pool:\n",
    "    args = [(xt_, rank, chunkSize, NUM_GPUS, currentInv, fisher, x) for x in range(NUM_GPUS)]\n",
    "    result = pool.starmap(trace_for_chunk, args)\n",
    "\n",
    "traceEst = np.frombuffer(tE.get_obj())\n",
    "\n",
    "## use 1 GPU\n",
    "# innerInv = torch.inverse(torch.eye(rank).cuda() + xt_ @ currentInv @ xt_.transpose(1, 2)).detach()\n",
    "# innerInv[torch.where(torch.isinf(innerInv))] = torch.sign(innerInv[torch.where(torch.isinf(innerInv))]) * np.finfo('float32').max\n",
    "# traceEst = torch.diagonal(xt_ @ currentInv @ fisher @ currentInv @ xt_.transpose(1, 2) @ innerInv, dim1=-2, dim2=-1).sum(-1)\n",
    "\n",
    "del fisher, currentInv, xt_, traceEst#, innerInv\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fisher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/usr/local/home/ast8hv/Documents/nn/gone-fishing/active_nn/query_strategies/checking_multiproc.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmow/usr/local/home/ast8hv/Documents/nn/gone-fishing/active_nn/query_strategies/checking_multiproc.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdel\u001b[39;00m fisher \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmow/usr/local/home/ast8hv/Documents/nn/gone-fishing/active_nn/query_strategies/checking_multiproc.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdel\u001b[39;00m currentInv \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmow/usr/local/home/ast8hv/Documents/nn/gone-fishing/active_nn/query_strategies/checking_multiproc.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdel\u001b[39;00m xt_\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fisher' is not defined"
     ]
    }
   ],
   "source": [
    "del fisher \n",
    "del currentInv \n",
    "del xt_\n",
    "del tE\n",
    "del innerInv\n",
    "del traceEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del pool\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
