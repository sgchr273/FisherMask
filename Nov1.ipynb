{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "model = resnet18(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "processed_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=preprocess)\n",
    "class_names = processed_trainset.classes\n",
    "processed_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=preprocess)\n",
    "dataloaders = {'train' : [], 'val' : []}\n",
    "dataloaders['train'] = torch.utils.data.DataLoader(processed_trainset, batch_size=100,\n",
    "                                                    shuffle=True, num_workers=4, pin_memory=True)\n",
    "dataloaders['val'] = torch.utils.data.DataLoader(processed_testset, batch_size=100,\n",
    "                                                    shuffle=False, num_workers=4, pin_memory=True)\n",
    "dataset_sizes = {'train' : len(processed_trainset), 'val' : len(processed_testset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finetune to Cifar10: Load the resnet18 model that has been pretrained on Imagenet.\n",
    "# Set requires_grad=False for all of the weights. Change its last layer (“fc”) to have only 10 outputs.\n",
    "#  The last layer weights will have requires_grad=True. \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(512, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "dataset_sizes = {'train' : 50000 , 'val' : 10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 1.1428 Acc: 0.6018\n",
      "val Loss: 1.1320 Acc: 0.6079\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 1.1255 Acc: 0.6088\n",
      "val Loss: 1.1245 Acc: 0.6096\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 1.1236 Acc: 0.6072\n",
      "val Loss: 1.1192 Acc: 0.6053\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 1.1270 Acc: 0.6069\n",
      "val Loss: 1.1178 Acc: 0.6036\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 1.1202 Acc: 0.6094\n",
      "val Loss: 1.1195 Acc: 0.6053\n",
      "\n",
      "Training complete in 2m 54s\n",
      "Best val Acc: 0.609600\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model, criterion, optimizer,\n",
    "                         exp_lr_scheduler, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.1218 Acc: 0.6086\n",
      "val Loss: 1.1110 Acc: 0.6168\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.1211 Acc: 0.6122\n",
      "val Loss: 1.1059 Acc: 0.6189\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.1163 Acc: 0.6102\n",
      "val Loss: 1.1140 Acc: 0.6157\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.1172 Acc: 0.6115\n",
      "val Loss: 1.1205 Acc: 0.6122\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.1169 Acc: 0.6099\n",
      "val Loss: 1.1317 Acc: 0.6057\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.1185 Acc: 0.6095\n",
      "val Loss: 1.1180 Acc: 0.6110\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.1175 Acc: 0.6097\n",
      "val Loss: 1.1018 Acc: 0.6152\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.1173 Acc: 0.6103\n",
      "val Loss: 1.1202 Acc: 0.6116\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.1142 Acc: 0.6085\n",
      "val Loss: 1.1076 Acc: 0.6168\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.1248 Acc: 0.6075\n",
      "val Loss: 1.1260 Acc: 0.6056\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 1.1209 Acc: 0.6084\n",
      "val Loss: 1.1045 Acc: 0.6205\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.1152 Acc: 0.6107\n",
      "val Loss: 1.1147 Acc: 0.6089\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.1205 Acc: 0.6084\n",
      "val Loss: 1.1078 Acc: 0.6110\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 1.1163 Acc: 0.6105\n",
      "val Loss: 1.1117 Acc: 0.6106\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 1.1144 Acc: 0.6130\n",
      "val Loss: 1.1136 Acc: 0.6144\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 1.1159 Acc: 0.6092\n",
      "val Loss: 1.1242 Acc: 0.6081\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 1.1139 Acc: 0.6095\n",
      "val Loss: 1.1010 Acc: 0.6158\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 1.1208 Acc: 0.6091\n",
      "val Loss: 1.1143 Acc: 0.6124\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 1.1200 Acc: 0.6101\n",
      "val Loss: 1.1199 Acc: 0.6115\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 1.1192 Acc: 0.6091\n",
      "val Loss: 1.1128 Acc: 0.6169\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 1.1150 Acc: 0.6097\n",
      "val Loss: 1.1026 Acc: 0.6137\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 1.1207 Acc: 0.6097\n",
      "val Loss: 1.1096 Acc: 0.6151\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 1.1154 Acc: 0.6079\n",
      "val Loss: 1.1040 Acc: 0.6178\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 1.1124 Acc: 0.6111\n",
      "val Loss: 1.1040 Acc: 0.6166\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 1.1206 Acc: 0.6081\n",
      "val Loss: 1.1157 Acc: 0.6180\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 1.1164 Acc: 0.6129\n",
      "val Loss: 1.1146 Acc: 0.6115\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 1.1184 Acc: 0.6135\n",
      "val Loss: 1.1022 Acc: 0.6106\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 1.1150 Acc: 0.6103\n",
      "val Loss: 1.1217 Acc: 0.6059\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 1.1123 Acc: 0.6129\n",
      "val Loss: 1.1223 Acc: 0.6070\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 1.1113 Acc: 0.6127\n",
      "val Loss: 1.1211 Acc: 0.6117\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 1.1164 Acc: 0.6096\n",
      "val Loss: 1.1240 Acc: 0.6064\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 1.1182 Acc: 0.6091\n",
      "val Loss: 1.1195 Acc: 0.6091\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 1.1233 Acc: 0.6067\n",
      "val Loss: 1.1226 Acc: 0.6066\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 1.1196 Acc: 0.6102\n",
      "val Loss: 1.1220 Acc: 0.6088\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 1.1184 Acc: 0.6143\n",
      "val Loss: 1.1283 Acc: 0.6062\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 1.1158 Acc: 0.6119\n",
      "val Loss: 1.1122 Acc: 0.6101\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 1.1129 Acc: 0.6129\n",
      "val Loss: 1.1286 Acc: 0.6061\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 1.1199 Acc: 0.6087\n",
      "val Loss: 1.1057 Acc: 0.6125\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 1.1162 Acc: 0.6096\n",
      "val Loss: 1.1196 Acc: 0.6138\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 1.1137 Acc: 0.6105\n",
      "val Loss: 1.1250 Acc: 0.6113\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 1.1206 Acc: 0.6100\n",
      "val Loss: 1.1166 Acc: 0.6077\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 1.1229 Acc: 0.6087\n",
      "val Loss: 1.1089 Acc: 0.6147\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 1.1186 Acc: 0.6104\n",
      "val Loss: 1.1201 Acc: 0.6089\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 1.1125 Acc: 0.6139\n",
      "val Loss: 1.1197 Acc: 0.6117\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 1.1127 Acc: 0.6117\n",
      "val Loss: 1.1170 Acc: 0.6074\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 1.1156 Acc: 0.6098\n",
      "val Loss: 1.1158 Acc: 0.6150\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 1.1195 Acc: 0.6103\n",
      "val Loss: 1.1410 Acc: 0.6015\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 1.1149 Acc: 0.6107\n",
      "val Loss: 1.1095 Acc: 0.6130\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 1.1146 Acc: 0.6123\n",
      "val Loss: 1.1230 Acc: 0.6094\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 1.1267 Acc: 0.6064\n",
      "val Loss: 1.1038 Acc: 0.6197\n",
      "\n",
      "Training complete in 29m 13s\n",
      "Best val Acc: 0.620500\n"
     ]
    }
   ],
   "source": [
    "#Use the cifar 10 training dataset to train the modified model for say 50 epochs.\n",
    "model_conv, hist = train_model(model, criterion, optimizer,\n",
    "                         exp_lr_scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    input_size = 224\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "outputs = model(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.1114 Acc: 0.6131\n",
      "val Loss: 1.1199 Acc: 0.6078\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.1152 Acc: 0.6107\n",
      "val Loss: 1.1238 Acc: 0.6050\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.1122 Acc: 0.6104\n",
      "val Loss: 1.1155 Acc: 0.6116\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.1192 Acc: 0.6106\n",
      "val Loss: 1.1091 Acc: 0.6123\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.1188 Acc: 0.6088\n",
      "val Loss: 1.1063 Acc: 0.6124\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.1133 Acc: 0.6113\n",
      "val Loss: 1.1220 Acc: 0.6021\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.1177 Acc: 0.6105\n",
      "val Loss: 1.0994 Acc: 0.6129\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.1145 Acc: 0.6118\n",
      "val Loss: 1.1130 Acc: 0.6131\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.1144 Acc: 0.6121\n",
      "val Loss: 1.1187 Acc: 0.6053\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.1187 Acc: 0.6102\n",
      "val Loss: 1.1215 Acc: 0.6062\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 1.1128 Acc: 0.6124\n",
      "val Loss: 1.1134 Acc: 0.6153\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.1135 Acc: 0.6150\n",
      "val Loss: 1.1177 Acc: 0.6063\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.1156 Acc: 0.6105\n",
      "val Loss: 1.1039 Acc: 0.6118\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 1.1138 Acc: 0.6124\n",
      "val Loss: 1.1261 Acc: 0.6109\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 1.1141 Acc: 0.6115\n",
      "val Loss: 1.1224 Acc: 0.6020\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 1.1191 Acc: 0.6084\n",
      "val Loss: 1.1163 Acc: 0.6180\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 1.1189 Acc: 0.6086\n",
      "val Loss: 1.1032 Acc: 0.6108\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 1.1213 Acc: 0.6079\n",
      "val Loss: 1.1165 Acc: 0.6096\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 1.1211 Acc: 0.6118\n",
      "val Loss: 1.1042 Acc: 0.6177\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 1.1193 Acc: 0.6062\n",
      "val Loss: 1.1172 Acc: 0.6117\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 1.1171 Acc: 0.6105\n",
      "val Loss: 1.1117 Acc: 0.6075\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 1.1170 Acc: 0.6102\n",
      "val Loss: 1.1133 Acc: 0.6103\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 1.1146 Acc: 0.6113\n",
      "val Loss: 1.1214 Acc: 0.6063\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 1.1211 Acc: 0.6077\n",
      "val Loss: 1.1129 Acc: 0.6091\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 1.1152 Acc: 0.6087\n",
      "val Loss: 1.1141 Acc: 0.6104\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 1.1170 Acc: 0.6104\n",
      "val Loss: 1.1232 Acc: 0.6082\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 1.1138 Acc: 0.6110\n",
      "val Loss: 1.1140 Acc: 0.6136\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 1.1179 Acc: 0.6127\n",
      "val Loss: 1.1084 Acc: 0.6106\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 1.1215 Acc: 0.6090\n",
      "val Loss: 1.1078 Acc: 0.6108\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 1.1170 Acc: 0.6112\n",
      "val Loss: 1.1005 Acc: 0.6179\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 1.1180 Acc: 0.6110\n",
      "val Loss: 1.1130 Acc: 0.6080\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 1.1233 Acc: 0.6076\n",
      "val Loss: 1.1120 Acc: 0.6131\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 1.1130 Acc: 0.6120\n",
      "val Loss: 1.1126 Acc: 0.6140\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 1.1174 Acc: 0.6090\n",
      "val Loss: 1.1163 Acc: 0.6094\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 1.1157 Acc: 0.6131\n",
      "val Loss: 1.1161 Acc: 0.6078\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 1.1151 Acc: 0.6097\n",
      "val Loss: 1.1132 Acc: 0.6076\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 1.1183 Acc: 0.6093\n",
      "val Loss: 1.1124 Acc: 0.6123\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 1.1140 Acc: 0.6136\n",
      "val Loss: 1.1248 Acc: 0.6131\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 1.1233 Acc: 0.6047\n",
      "val Loss: 1.1203 Acc: 0.6088\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 1.1234 Acc: 0.6068\n",
      "val Loss: 1.1176 Acc: 0.6064\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 1.1181 Acc: 0.6124\n",
      "val Loss: 1.1046 Acc: 0.6116\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 1.1118 Acc: 0.6116\n",
      "val Loss: 1.1166 Acc: 0.6133\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 1.1264 Acc: 0.6049\n",
      "val Loss: 1.1283 Acc: 0.6043\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 1.1122 Acc: 0.6127\n",
      "val Loss: 1.1234 Acc: 0.6033\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 1.1203 Acc: 0.6095\n",
      "val Loss: 1.1115 Acc: 0.6107\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 1.1176 Acc: 0.6109\n",
      "val Loss: 1.1196 Acc: 0.6037\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 1.1212 Acc: 0.6079\n",
      "val Loss: 1.1241 Acc: 0.6072\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 1.1081 Acc: 0.6154\n",
      "val Loss: 1.1001 Acc: 0.6187\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 1.1144 Acc: 0.6103\n",
      "val Loss: 1.1060 Acc: 0.6145\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 1.1182 Acc: 0.6101\n",
      "val Loss: 1.1154 Acc: 0.6076\n",
      "\n",
      "Training complete in 29m 8s\n",
      "Best val Acc: 0.618700\n"
     ]
    }
   ],
   "source": [
    "scratch_model,_ = initialize_model(model, num_classes = 10, feature_extract=False, use_pretrained=False)\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "_,scratch_hist = train_model(model, criterion, optimizer,\n",
    "                         exp_lr_scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find important weights: For the model trained above, set requires_grad=True for all the weights.\n",
    "# Compute the gradients for each weight for images in the cifar 10 test set.\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for inputs, labels in dataloaders['val']:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pyt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Oct 21 2022, 23:50:54) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4cafaace53dbfa2f2f80725cf8b8a707efc1de97ef1c6af3883bc118682f6610"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
