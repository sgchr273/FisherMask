{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#download the dataset cifar10, and create a dataloader with appropriate preprocessing\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "processed_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=preprocess)\n",
    "class_names = processed_trainset.classes\n",
    "processed_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=preprocess)\n",
    "dataloaders = {'train' : [], 'val' : []}\n",
    "dataloaders['train'] = torch.utils.data.DataLoader(processed_trainset, batch_size=100,\n",
    "                                                    shuffle=True, num_workers=4, pin_memory=True)\n",
    "dataloaders['val'] = torch.utils.data.DataLoader(processed_testset, batch_size=100,\n",
    "                                                    shuffle=False, num_workers=4, pin_memory=True)\n",
    "dataset_sizes = {'train' : len(processed_trainset), 'val' : len(processed_testset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finetune to Cifar10: Load the resnet18 model that has been pretrained on Imagenet.\n",
    "# Set requires_grad=False for all of the weights. Change its last layer (“fc”) to have only 10 outputs. The last layer weights will have requires_grad=True. \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "dataset_sizes = 50,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 1.5574 Acc: 0.4606\n",
      "val Loss: 1.3334 Acc: 0.5427\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 1.2765 Acc: 0.5629\n",
      "val Loss: 1.2346 Acc: 0.5718\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 1.2151 Acc: 0.5782\n",
      "val Loss: 1.1863 Acc: 0.5880\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 1.1860 Acc: 0.5898\n",
      "val Loss: 1.1811 Acc: 0.5905\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 1.1875 Acc: 0.5917\n",
      "val Loss: 1.1880 Acc: 0.5854\n",
      "\n",
      "Training complete in 8m 6s\n",
      "Best val Acc: 0.590500\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model, criterion, optimizer,\n",
    "                         exp_lr_scheduler, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.2134 Acc: 0.5857\n",
      "val Loss: 1.1957 Acc: 0.5881\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.2064 Acc: 0.5843\n",
      "val Loss: 1.2004 Acc: 0.5920\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.1974 Acc: 0.5914\n",
      "val Loss: 1.1925 Acc: 0.5825\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.1894 Acc: 0.5917\n",
      "val Loss: 1.1723 Acc: 0.5935\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.1913 Acc: 0.5903\n",
      "val Loss: 1.1740 Acc: 0.5916\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.1903 Acc: 0.5911\n",
      "val Loss: 1.1885 Acc: 0.5886\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.1914 Acc: 0.5931\n",
      "val Loss: 1.1783 Acc: 0.5935\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.1905 Acc: 0.5906\n",
      "val Loss: 1.1818 Acc: 0.5912\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.1902 Acc: 0.5891\n",
      "val Loss: 1.1711 Acc: 0.5971\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.1892 Acc: 0.5889\n",
      "val Loss: 1.1856 Acc: 0.5945\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 1.1868 Acc: 0.5902\n",
      "val Loss: 1.1702 Acc: 0.5980\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.1873 Acc: 0.5923\n",
      "val Loss: 1.1890 Acc: 0.5913\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.1888 Acc: 0.5915\n",
      "val Loss: 1.1741 Acc: 0.5991\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 1.1828 Acc: 0.5929\n",
      "val Loss: 1.1713 Acc: 0.5979\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 1.1849 Acc: 0.5935\n",
      "val Loss: 1.1792 Acc: 0.5960\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 1.1863 Acc: 0.5925\n",
      "val Loss: 1.1814 Acc: 0.5928\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 1.1911 Acc: 0.5899\n",
      "val Loss: 1.1862 Acc: 0.5908\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 1.1855 Acc: 0.5894\n",
      "val Loss: 1.1846 Acc: 0.5905\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 1.1864 Acc: 0.5913\n",
      "val Loss: 1.1785 Acc: 0.5957\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 1.1825 Acc: 0.5936\n",
      "val Loss: 1.1793 Acc: 0.5961\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 1.1857 Acc: 0.5910\n",
      "val Loss: 1.1806 Acc: 0.5991\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 1.1864 Acc: 0.5911\n",
      "val Loss: 1.1689 Acc: 0.5957\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 1.1854 Acc: 0.5916\n",
      "val Loss: 1.1655 Acc: 0.6021\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 1.1825 Acc: 0.5932\n",
      "val Loss: 1.1769 Acc: 0.5984\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 1.1787 Acc: 0.5946\n",
      "val Loss: 1.1887 Acc: 0.5877\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 1.1855 Acc: 0.5923\n",
      "val Loss: 1.2000 Acc: 0.5829\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 1.1834 Acc: 0.5924\n",
      "val Loss: 1.1713 Acc: 0.5983\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 1.1832 Acc: 0.5930\n",
      "val Loss: 1.1724 Acc: 0.5960\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 1.1893 Acc: 0.5895\n",
      "val Loss: 1.1724 Acc: 0.5943\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 1.1847 Acc: 0.5929\n",
      "val Loss: 1.1850 Acc: 0.5910\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 1.1852 Acc: 0.5944\n",
      "val Loss: 1.1819 Acc: 0.5930\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 1.1863 Acc: 0.5935\n",
      "val Loss: 1.1756 Acc: 0.5927\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 1.1832 Acc: 0.5922\n",
      "val Loss: 1.1771 Acc: 0.5939\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 1.1867 Acc: 0.5918\n",
      "val Loss: 1.1668 Acc: 0.6005\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 1.1839 Acc: 0.5925\n",
      "val Loss: 1.1857 Acc: 0.5911\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 1.1856 Acc: 0.5928\n",
      "val Loss: 1.1776 Acc: 0.5899\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 1.1854 Acc: 0.5937\n",
      "val Loss: 1.1727 Acc: 0.5944\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 1.1859 Acc: 0.5935\n",
      "val Loss: 1.1727 Acc: 0.5948\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 1.1878 Acc: 0.5899\n",
      "val Loss: 1.1696 Acc: 0.5942\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 1.1840 Acc: 0.5918\n",
      "val Loss: 1.1860 Acc: 0.5864\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 1.1897 Acc: 0.5888\n",
      "val Loss: 1.1738 Acc: 0.5900\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 1.1800 Acc: 0.5937\n",
      "val Loss: 1.1895 Acc: 0.5897\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 1.1899 Acc: 0.5914\n",
      "val Loss: 1.1799 Acc: 0.5900\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 1.1828 Acc: 0.5962\n",
      "val Loss: 1.1896 Acc: 0.5886\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 1.1834 Acc: 0.5897\n",
      "val Loss: 1.1687 Acc: 0.6005\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 1.1884 Acc: 0.5888\n",
      "val Loss: 1.1770 Acc: 0.5959\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 1.1871 Acc: 0.5924\n",
      "val Loss: 1.1739 Acc: 0.5913\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 1.1867 Acc: 0.5905\n",
      "val Loss: 1.1848 Acc: 0.5941\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 1.1888 Acc: 0.5903\n",
      "val Loss: 1.1809 Acc: 0.5945\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 1.1856 Acc: 0.5937\n",
      "val Loss: 1.1796 Acc: 0.5968\n",
      "\n",
      "Training complete in 80m 10s\n",
      "Best val Acc: 0.602100\n"
     ]
    }
   ],
   "source": [
    "#Use the cifar 10 training dataset to train the modified model for say 50 epochs.\n",
    "model_conv = train_model(model, criterion, optimizer,\n",
    "                         exp_lr_scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    input_size = 224\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 9.7918 Acc: 0.0013\n",
      "val Loss: 9.8673 Acc: 0.0016\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 9.7786 Acc: 0.0013\n",
      "val Loss: 9.8887 Acc: 0.0011\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 9.7768 Acc: 0.0014\n",
      "val Loss: 9.7829 Acc: 0.0011\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 9.7830 Acc: 0.0012\n",
      "val Loss: 9.8845 Acc: 0.0015\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 9.7909 Acc: 0.0012\n",
      "val Loss: 9.8258 Acc: 0.0011\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 9.7845 Acc: 0.0012\n",
      "val Loss: 9.8410 Acc: 0.0019\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 9.7925 Acc: 0.0015\n",
      "val Loss: 9.8342 Acc: 0.0015\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 9.7825 Acc: 0.0011\n",
      "val Loss: 9.8381 Acc: 0.0018\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 9.7891 Acc: 0.0012\n",
      "val Loss: 9.7886 Acc: 0.0015\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 9.7762 Acc: 0.0014\n",
      "val Loss: 9.7538 Acc: 0.0016\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 9.7815 Acc: 0.0011\n",
      "val Loss: 9.8740 Acc: 0.0015\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 9.7915 Acc: 0.0013\n",
      "val Loss: 9.8090 Acc: 0.0018\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 9.7789 Acc: 0.0013\n",
      "val Loss: 9.8263 Acc: 0.0017\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 9.7785 Acc: 0.0013\n",
      "val Loss: 9.8270 Acc: 0.0019\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 9.7809 Acc: 0.0013\n",
      "val Loss: 9.8517 Acc: 0.0015\n",
      "\n",
      "Training complete in 23m 53s\n",
      "Best val Acc: 0.001900\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable ResNet object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [59], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m scratch_optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(scratch_model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[1;32m      4\u001b[0m scratch_criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 5\u001b[0m _,scratch_hist \u001b[39m=\u001b[39m train_model(model, criterion, optimizer,\n\u001b[1;32m      6\u001b[0m                          exp_lr_scheduler, num_epochs\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable ResNet object"
     ]
    }
   ],
   "source": [
    "scratch_model,_ = initialize_model(model, num_classes = 10, feature_extract=False, use_pretrained=False)\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "_,scratch_hist = train_model(model, criterion, optimizer,\n",
    "                         exp_lr_scheduler, num_epochs=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pyt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4cafaace53dbfa2f2f80725cf8b8a707efc1de97ef1c6af3883bc118682f6610"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
