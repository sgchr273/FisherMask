{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "from scipy import stats\n",
    "from torch.multiprocessing import Pool\n",
    "dim = 10 * 100 #X.shape[-1]\n",
    "rank = 10 #X.shape[-2]\n",
    "fisher = torch.rand((dim, dim)).cuda()\n",
    "currentInv = torch.rand((dim, dim)).cuda()\n",
    "xt = torch.rand((100, rank, dim)).cuda()\n",
    "n = 10 #nquery\n",
    "init = []\n",
    "n_pool = 100 #debug size\n",
    "idxs_lb = np.zeros(n_pool, dtype=bool)\n",
    "## using 2 GPUs\n",
    "chunkSize = 50\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "torch.multiprocessing.set_start_method('spawn', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betterSlice(num_gpus, gpu_id, total_len):\n",
    "    upper_bound = int(total_len/(num_gpus-gpu_id))\n",
    "    lower_bound = int(upper_bound-(total_len/num_gpus))\n",
    "    return slice(lower_bound, upper_bound)\n",
    "\n",
    "def trace_for_chunk(xt_, rank, num_gpus, chunkSize, currentInv, fisher, total_len, gpu_id):\n",
    "    traceEst = torch.zeros((total_len//num_gpus))\n",
    "    for c_idx in range(len(xt_), chunkSize):\n",
    "        xt_chunk = xt_[c_idx : c_idx + chunkSize]\n",
    "        xt_chunk = xt_chunk.cuda(gpu_id)\n",
    "        fisher = fisher.cuda(gpu_id)\n",
    "        currentInv = currentInv.cuda(gpu_id)\n",
    "        # with torch.no_grad():\n",
    "        innerInv = torch.inverse(torch.eye(rank).cuda(gpu_id) + xt_chunk @ currentInv @ xt_chunk.transpose(1, 2)) \n",
    "        traceEst[c_idx : c_idx + chunkSize] = torch.diagonal(\n",
    "            xt_chunk @ currentInv @ fisher @ currentInv @ xt_chunk.transpose(1, 2) @ innerInv,\n",
    "            dim1=-2,\n",
    "            dim2=-1\n",
    "        ).sum(-1).detach().cpu()\n",
    "    return traceEst\n",
    "\n",
    "def select(X, K, fisher, iterates, savefile, alg, lamb=1, backwardSteps=0, nLabeled=0, chunkSize=200):\n",
    "    '''\n",
    "    K is the number of images to be selected for labelling, \n",
    "    iterates is the fisher for images that are already labelled\n",
    "    '''\n",
    "    time_begin_select = time.time()\n",
    "    numEmbs = len(X)\n",
    "    dim = X.shape[-1]\n",
    "    rank = X.shape[-2]\n",
    "    indsAll = []\n",
    "    currentInv = torch.rand((dim, dim)).cuda()\n",
    "    #currentInv = torch.inverse(lamb * torch.eye(dim).cuda() + iterates.cuda() * nLabeled / (nLabeled + K))\n",
    "    X = X * np.sqrt(K / (nLabeled + K))\n",
    "    xt_ = X\n",
    "    chunkSize = min(X.shape[0], chunkSize)\n",
    "    total_len = xt_.shape[0]\n",
    "    NUM_GPUS = torch.cuda.device_count()\n",
    "    fishers = [fisher.clone().detach().cuda(x) for x in range(NUM_GPUS)]\n",
    "    xts = [X[betterSlice(NUM_GPUS, x, total_len)].clone().detach().cuda(x) for x in range(NUM_GPUS)]\n",
    "    torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "    distStats = []\n",
    "\n",
    "    with Pool(processes=NUM_GPUS) as pool:\n",
    "        for i in range(int((backwardSteps + 1) *  K)):\n",
    "            cInvs = [currentInv.clone().detach().cuda(x) for x in range(NUM_GPUS)]\n",
    "            args = [(xts[x], rank, NUM_GPUS, chunkSize, cInvs[x], fishers[x], total_len, x) for x in range(NUM_GPUS)]\n",
    "            tE = pool.starmap(trace_for_chunk, args)\n",
    "            traceEst = tE[0]\n",
    "            for j in range(1,NUM_GPUS):\n",
    "                traceEst = torch.cat((traceEst, tE[j]))\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            traceEst = traceEst.detach().cpu().numpy()\n",
    "\n",
    "            dist = traceEst - np.min(traceEst) + 1e-10\n",
    "            dist = dist / np.sum(dist)\n",
    "            distStats.append([np.min(dist), np.max(dist), np.std(dist)])\n",
    "            sampler = stats.rv_discrete(values=(np.arange(len(dist)), dist))\n",
    "            ind = sampler.rvs(size=1)[0]\n",
    "            for j in np.argsort(dist)[::-1]:\n",
    "                if j not in indsAll:\n",
    "                    ind = j\n",
    "                    break\n",
    "\n",
    "            indsAll.append(ind)\n",
    "            temp_xt = X[ind].unsqueeze(0).cuda()\n",
    "            innerInv = torch.inverse(torch.eye(rank).cuda(0) + temp_xt @ cInvs[0] @ temp_xt.transpose(1, 2)).detach()\n",
    "            currentInv = (cInvs[0] - cInvs[0] @ temp_xt.transpose(1, 2) @ innerInv @ temp_xt @ cInvs[0]).detach()[0]\n",
    "    \n",
    "    for i in range(len(indsAll) - K):\n",
    "        # select index for removal\n",
    "        xt_ = torch.tensor(X[indsAll]).cuda()\n",
    "        innerInv = torch.inverse(-1 * torch.eye(rank).cuda() + xt_ @ currentInv @ xt_.transpose(1, 2)).detach()\n",
    "        traceEst = torch.diagonal(xt_ @ currentInv @ fisher @ currentInv @ xt_.transpose(1, 2) @ innerInv, dim1=-2, dim2=-1).sum(-1)\n",
    "        delInd = torch.argmin(-1 * traceEst).item()\n",
    "\n",
    "        # compute new inverse\n",
    "        xt_ = torch.tensor(X[indsAll[delInd]]).unsqueeze(0).cuda()\n",
    "        innerInv = torch.inverse(-1 * torch.eye(rank).cuda() + xt_ @ currentInv @ xt_.transpose(1, 2)).detach()\n",
    "        currentInv = (currentInv - currentInv @ xt_.transpose(1, 2) @ innerInv @ xt_ @ currentInv).detach()[0]\n",
    "\n",
    "        del indsAll[delInd]\n",
    "\n",
    "    del xt_, innerInv, currentInv, tE, traceEst\n",
    "    #save_dist_stats(distStats, savefile, alg)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    time_end_select = time.time()\n",
    "    #logging.debug(\"Select took\" + str(time_end_select - time_begin_select) + \"seconds\")\n",
    "    return indsAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(X, K, fisher, iterates, lamb=1, backwardSteps=0, nLabeled=0):\n",
    "\n",
    "    numEmbs = len(X)\n",
    "    indsAll = []\n",
    "    dim = X.shape[-1]\n",
    "    rank = X.shape[-2]\n",
    "\n",
    "    currentInv = torch.inverse(lamb * torch.eye(dim).cuda() + iterates.cuda() * nLabeled / (nLabeled + K))\n",
    "    X = X * np.sqrt(K / (nLabeled + K))\n",
    "    fisher = fisher.cuda()\n",
    "\n",
    "    # forward selection\n",
    "    for i in range(int((backwardSteps + 1) *  K)):\n",
    "\n",
    "        xt_ = X.cuda() \n",
    "        innerInv = torch.inverse(torch.eye(rank).cuda() + xt_ @ currentInv @ xt_.transpose(1, 2)).detach()\n",
    "        innerInv[torch.where(torch.isinf(innerInv))] = torch.sign(innerInv[torch.where(torch.isinf(innerInv))]) * np.finfo('float32').max\n",
    "        traceEst = torch.diagonal(xt_ @ currentInv @ fisher @ currentInv @ xt_.transpose(1, 2) @ innerInv, dim1=-2, dim2=-1).sum(-1)\n",
    "\n",
    "        xt = xt_.cpu()\n",
    "        del xt, innerInv\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        traceEst = traceEst.detach().cpu().numpy()\n",
    "\n",
    "        dist = traceEst - np.min(traceEst) + 1e-10\n",
    "        dist = dist / np.sum(dist)\n",
    "        sampler = stats.rv_discrete(values=(np.arange(len(dist)), dist))\n",
    "        ind = sampler.rvs(size=1)[0]\n",
    "        for j in np.argsort(dist)[::-1]:\n",
    "            if j not in indsAll:\n",
    "                ind = j\n",
    "                break\n",
    "\n",
    "        indsAll.append(ind)\n",
    "        print(i, ind, traceEst[ind], flush=True)\n",
    "       \n",
    "        xt_ = X[ind].unsqueeze(0).cuda()\n",
    "        innerInv = torch.inverse(torch.eye(rank).cuda() + xt_ @ currentInv @ xt_.transpose(1, 2)).detach()\n",
    "        currentInv = (currentInv - currentInv @ xt_.transpose(1, 2) @ innerInv @ xt_ @ currentInv).detach()[0]\n",
    "\n",
    "    # backward pruning\n",
    "    for i in range(len(indsAll) - K):\n",
    "\n",
    "        # select index for removal\n",
    "        xt_ = X[indsAll].cuda()\n",
    "        innerInv = torch.inverse(-1 * torch.eye(rank).cuda() + xt_ @ currentInv @ xt_.transpose(1, 2)).detach()\n",
    "        traceEst = torch.diagonal(xt_ @ currentInv @ fisher @ currentInv @ xt_.transpose(1, 2) @ innerInv, dim1=-2, dim2=-1).sum(-1)\n",
    "        delInd = torch.argmin(-1 * traceEst).item()\n",
    "        print(i, indsAll[delInd], -1 * traceEst[delInd].item(), flush=True)\n",
    "\n",
    "\n",
    "        # compute new inverse\n",
    "        xt_ = X[indsAll[delInd]].unsqueeze(0).cuda()\n",
    "        innerInv = torch.inverse(-1 * torch.eye(rank).cuda() + xt_ @ currentInv @ xt_.transpose(1, 2)).detach()\n",
    "        currentInv = (currentInv - currentInv @ xt_.transpose(1, 2) @ innerInv @ xt_ @ currentInv).detach()[0]\n",
    "\n",
    "        del indsAll[delInd]\n",
    "\n",
    "    del xt_, innerInv, currentInv\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return indsAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chosen = select(xt, n, fisher, init, \"savefile\", \"FISH\", lamb=1, backwardSteps=0, nLabeled=np.sum(idxs_lb), chunkSize=chunkSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------size 24000-------\n",
      "gpu 0: (slice(0, 8000, None))\n",
      "gpu 1: (slice(8000, 16000, None))\n",
      "gpu 2: (slice(16000, 24000, None))\n",
      "-------size 22000-------\n",
      "gpu 0: (slice(0, 7333, None))\n",
      "gpu 1: (slice(7333, 14666, None))\n",
      "gpu 2: (slice(14666, 22000, None))\n",
      "-------size 20000-------\n",
      "gpu 0: (slice(0, 6666, None))\n",
      "gpu 1: (slice(6666, 13333, None))\n",
      "gpu 2: (slice(13333, 20000, None))\n",
      "-------size 18000-------\n",
      "gpu 0: (slice(0, 6000, None))\n",
      "gpu 1: (slice(6000, 12000, None))\n",
      "gpu 2: (slice(12000, 18000, None))\n",
      "-------size 16000-------\n",
      "gpu 0: (slice(0, 5333, None))\n",
      "gpu 1: (slice(5333, 10666, None))\n",
      "gpu 2: (slice(10666, 16000, None))\n",
      "-------size 14000-------\n",
      "gpu 0: (slice(0, 4666, None))\n",
      "gpu 1: (slice(4666, 9333, None))\n",
      "gpu 2: (slice(9333, 14000, None))\n",
      "-------size 12000-------\n",
      "gpu 0: (slice(0, 4000, None))\n",
      "gpu 1: (slice(4000, 8000, None))\n",
      "gpu 2: (slice(8000, 12000, None))\n",
      "-------size 10000-------\n",
      "gpu 0: (slice(0, 3333, None))\n",
      "gpu 1: (slice(3333, 6666, None))\n",
      "gpu 2: (slice(6666, 10000, None))\n",
      "-------size 8000-------\n",
      "gpu 0: (slice(0, 2666, None))\n",
      "gpu 1: (slice(2666, 5333, None))\n",
      "gpu 2: (slice(5333, 8000, None))\n",
      "-------size 6000-------\n",
      "gpu 0: (slice(0, 2000, None))\n",
      "gpu 1: (slice(2000, 4000, None))\n",
      "gpu 2: (slice(4000, 6000, None))\n",
      "-------size 4000-------\n",
      "gpu 0: (slice(0, 1333, None))\n",
      "gpu 1: (slice(1333, 2666, None))\n",
      "gpu 2: (slice(2666, 4000, None))\n",
      "-------size 2000-------\n",
      "gpu 0: (slice(0, 666, None))\n",
      "gpu 1: (slice(666, 1333, None))\n",
      "gpu 2: (slice(1333, 2000, None))\n"
     ]
    }
   ],
   "source": [
    "\"\"\" def betterSlice(num_gpus, gpu_id, total_len):\n",
    "    upper_bound = int(total_len/(num_gpus-gpu_id))\n",
    "    lower_bound = int(upper_bound-(total_len/num_gpus))\n",
    "    return slice(lower_bound, upper_bound) \"\"\"\n",
    "\n",
    "def betterSlice(num_gpus, gpu_id, total_len):\n",
    "    upper_bound = (1+gpu_id)*total_len/num_gpus\n",
    "    lower_bound = upper_bound-(total_len/num_gpus)\n",
    "    return slice(int(lower_bound), int(upper_bound))\n",
    "\n",
    "#for i in range(1,5):\n",
    "    #print(f\"-----------{i} gpus-----------\")\n",
    "i = 3\n",
    "for k in range(24000,0,-2000):\n",
    "    print(f\"-------size {k}-------\")\n",
    "    for j in range(i):\n",
    "        sliced = betterSlice(i,j,k)\n",
    "        print(f\"gpu {j}: ({sliced})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
