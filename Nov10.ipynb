{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/home/sgchr/anaconda3/envs/pyt/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/home/sgchr/anaconda3/envs/pyt/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/usr/local/home/sgchr/anaconda3/envs/pyt/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/home/sgchr/anaconda3/envs/pyt/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "model = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "preprocess = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "processed_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=preprocess)\n",
    "class_names = processed_trainset.classes\n",
    "processed_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=preprocess)\n",
    "dataloaders = {'train' : [], 'val' : []}\n",
    "dataloaders['train'] = torch.utils.data.DataLoader(processed_trainset, batch_size=100,\n",
    "                                                    shuffle=True, num_workers=4, pin_memory=True)\n",
    "dataloaders['val'] = torch.utils.data.DataLoader(processed_testset, batch_size=100,\n",
    "                                                    shuffle=False, num_workers=4, pin_memory=True)\n",
    "dataset_sizes = {'train' : len(processed_trainset), 'val' : len(processed_testset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/home/sgchr/anaconda3/envs/pyt/lib/python3.8/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(512, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([64, 3, 7, 7]) False\n",
      "bn1.weight torch.Size([64]) False\n",
      "bn1.bias torch.Size([64]) False\n",
      "layer1.0.conv1.weight torch.Size([64, 64, 3, 3]) False\n",
      "layer1.0.bn1.weight torch.Size([64]) False\n",
      "layer1.0.bn1.bias torch.Size([64]) False\n",
      "layer1.0.conv2.weight torch.Size([64, 64, 3, 3]) False\n",
      "layer1.0.bn2.weight torch.Size([64]) False\n",
      "layer1.0.bn2.bias torch.Size([64]) False\n",
      "layer1.1.conv1.weight torch.Size([64, 64, 3, 3]) False\n",
      "layer1.1.bn1.weight torch.Size([64]) False\n",
      "layer1.1.bn1.bias torch.Size([64]) False\n",
      "layer1.1.conv2.weight torch.Size([64, 64, 3, 3]) False\n",
      "layer1.1.bn2.weight torch.Size([64]) False\n",
      "layer1.1.bn2.bias torch.Size([64]) False\n",
      "layer2.0.conv1.weight torch.Size([128, 64, 3, 3]) False\n",
      "layer2.0.bn1.weight torch.Size([128]) False\n",
      "layer2.0.bn1.bias torch.Size([128]) False\n",
      "layer2.0.conv2.weight torch.Size([128, 128, 3, 3]) False\n",
      "layer2.0.bn2.weight torch.Size([128]) False\n",
      "layer2.0.bn2.bias torch.Size([128]) False\n",
      "layer2.0.downsample.0.weight torch.Size([128, 64, 1, 1]) False\n",
      "layer2.0.downsample.1.weight torch.Size([128]) False\n",
      "layer2.0.downsample.1.bias torch.Size([128]) False\n",
      "layer2.1.conv1.weight torch.Size([128, 128, 3, 3]) False\n",
      "layer2.1.bn1.weight torch.Size([128]) False\n",
      "layer2.1.bn1.bias torch.Size([128]) False\n",
      "layer2.1.conv2.weight torch.Size([128, 128, 3, 3]) False\n",
      "layer2.1.bn2.weight torch.Size([128]) False\n",
      "layer2.1.bn2.bias torch.Size([128]) False\n",
      "layer3.0.conv1.weight torch.Size([256, 128, 3, 3]) False\n",
      "layer3.0.bn1.weight torch.Size([256]) False\n",
      "layer3.0.bn1.bias torch.Size([256]) False\n",
      "layer3.0.conv2.weight torch.Size([256, 256, 3, 3]) False\n",
      "layer3.0.bn2.weight torch.Size([256]) False\n",
      "layer3.0.bn2.bias torch.Size([256]) False\n",
      "layer3.0.downsample.0.weight torch.Size([256, 128, 1, 1]) False\n",
      "layer3.0.downsample.1.weight torch.Size([256]) False\n",
      "layer3.0.downsample.1.bias torch.Size([256]) False\n",
      "layer3.1.conv1.weight torch.Size([256, 256, 3, 3]) False\n",
      "layer3.1.bn1.weight torch.Size([256]) False\n",
      "layer3.1.bn1.bias torch.Size([256]) False\n",
      "layer3.1.conv2.weight torch.Size([256, 256, 3, 3]) False\n",
      "layer3.1.bn2.weight torch.Size([256]) False\n",
      "layer3.1.bn2.bias torch.Size([256]) False\n",
      "layer4.0.conv1.weight torch.Size([512, 256, 3, 3]) False\n",
      "layer4.0.bn1.weight torch.Size([512]) False\n",
      "layer4.0.bn1.bias torch.Size([512]) False\n",
      "layer4.0.conv2.weight torch.Size([512, 512, 3, 3]) False\n",
      "layer4.0.bn2.weight torch.Size([512]) False\n",
      "layer4.0.bn2.bias torch.Size([512]) False\n",
      "layer4.0.downsample.0.weight torch.Size([512, 256, 1, 1]) False\n",
      "layer4.0.downsample.1.weight torch.Size([512]) False\n",
      "layer4.0.downsample.1.bias torch.Size([512]) False\n",
      "layer4.1.conv1.weight torch.Size([512, 512, 3, 3]) False\n",
      "layer4.1.bn1.weight torch.Size([512]) False\n",
      "layer4.1.bn1.bias torch.Size([512]) False\n",
      "layer4.1.conv2.weight torch.Size([512, 512, 3, 3]) False\n",
      "layer4.1.bn2.weight torch.Size([512]) False\n",
      "layer4.1.bn2.bias torch.Size([512]) False\n",
      "fc.weight torch.Size([10, 512]) True\n",
      "fc.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "dataset_sizes = {'train' : 50000 , 'val' : 10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.5573 Acc: 0.4755\n",
      "val Loss: 1.2833 Acc: 0.5643\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.2487 Acc: 0.5692\n",
      "val Loss: 1.2197 Acc: 0.5738\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.1958 Acc: 0.5866\n",
      "val Loss: 1.1761 Acc: 0.5941\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.1662 Acc: 0.5947\n",
      "val Loss: 1.1498 Acc: 0.5979\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.1536 Acc: 0.5989\n",
      "val Loss: 1.1319 Acc: 0.6074\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.1397 Acc: 0.6027\n",
      "val Loss: 1.1342 Acc: 0.5991\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.1261 Acc: 0.6058\n",
      "val Loss: 1.1047 Acc: 0.6150\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.1181 Acc: 0.6078\n",
      "val Loss: 1.1156 Acc: 0.6116\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.1181 Acc: 0.6098\n",
      "val Loss: 1.1167 Acc: 0.6140\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.1188 Acc: 0.6117\n",
      "val Loss: 1.1034 Acc: 0.6170\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 1.1180 Acc: 0.6097\n",
      "val Loss: 1.1280 Acc: 0.6049\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.1182 Acc: 0.6111\n",
      "val Loss: 1.1270 Acc: 0.6100\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.1157 Acc: 0.6079\n",
      "val Loss: 1.1180 Acc: 0.6119\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 1.1163 Acc: 0.6089\n",
      "val Loss: 1.1039 Acc: 0.6095\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 1.1125 Acc: 0.6124\n",
      "val Loss: 1.1075 Acc: 0.6121\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 1.1163 Acc: 0.6099\n",
      "val Loss: 1.1128 Acc: 0.6103\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 1.1174 Acc: 0.6097\n",
      "val Loss: 1.1082 Acc: 0.6109\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 1.1149 Acc: 0.6123\n",
      "val Loss: 1.1011 Acc: 0.6154\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 1.1092 Acc: 0.6093\n",
      "val Loss: 1.1147 Acc: 0.6086\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 1.1107 Acc: 0.6123\n",
      "val Loss: 1.1139 Acc: 0.6116\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 1.1138 Acc: 0.6098\n",
      "val Loss: 1.1191 Acc: 0.6118\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 1.1115 Acc: 0.6142\n",
      "val Loss: 1.1061 Acc: 0.6089\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 1.1056 Acc: 0.6147\n",
      "val Loss: 1.1084 Acc: 0.6082\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 1.1206 Acc: 0.6089\n",
      "val Loss: 1.1060 Acc: 0.6117\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 1.1179 Acc: 0.6102\n",
      "val Loss: 1.1117 Acc: 0.6054\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 1.1149 Acc: 0.6124\n",
      "val Loss: 1.1306 Acc: 0.6073\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 1.1152 Acc: 0.6107\n",
      "val Loss: 1.0955 Acc: 0.6163\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 1.1146 Acc: 0.6134\n",
      "val Loss: 1.1202 Acc: 0.6113\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 1.1126 Acc: 0.6122\n",
      "val Loss: 1.1182 Acc: 0.6126\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 1.1096 Acc: 0.6128\n",
      "val Loss: 1.0936 Acc: 0.6150\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 1.1114 Acc: 0.6124\n",
      "val Loss: 1.1047 Acc: 0.6092\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 1.1131 Acc: 0.6113\n",
      "val Loss: 1.1106 Acc: 0.6087\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 1.1166 Acc: 0.6105\n",
      "val Loss: 1.1144 Acc: 0.6112\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 1.1102 Acc: 0.6122\n",
      "val Loss: 1.1194 Acc: 0.6070\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 1.1068 Acc: 0.6144\n",
      "val Loss: 1.1161 Acc: 0.6062\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 1.1144 Acc: 0.6099\n",
      "val Loss: 1.1019 Acc: 0.6143\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 1.1172 Acc: 0.6112\n",
      "val Loss: 1.0919 Acc: 0.6167\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 1.1141 Acc: 0.6095\n",
      "val Loss: 1.1141 Acc: 0.6171\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 1.1160 Acc: 0.6133\n",
      "val Loss: 1.0977 Acc: 0.6164\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 1.1149 Acc: 0.6097\n",
      "val Loss: 1.1146 Acc: 0.6064\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 1.1081 Acc: 0.6148\n",
      "val Loss: 1.1183 Acc: 0.6091\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 1.1137 Acc: 0.6112\n",
      "val Loss: 1.1024 Acc: 0.6203\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 1.1134 Acc: 0.6116\n",
      "val Loss: 1.0983 Acc: 0.6139\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 1.1085 Acc: 0.6132\n",
      "val Loss: 1.1123 Acc: 0.6054\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 1.1151 Acc: 0.6104\n",
      "val Loss: 1.1078 Acc: 0.6102\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 1.1156 Acc: 0.6126\n",
      "val Loss: 1.1098 Acc: 0.6106\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 1.1121 Acc: 0.6116\n",
      "val Loss: 1.1148 Acc: 0.6104\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 1.1200 Acc: 0.6108\n",
      "val Loss: 1.1036 Acc: 0.6146\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 1.1170 Acc: 0.6101\n",
      "val Loss: 1.1168 Acc: 0.6108\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 1.1173 Acc: 0.6090\n",
      "val Loss: 1.1086 Acc: 0.6097\n",
      "\n",
      "Training complete in 28m 44s\n",
      "Best val Acc: 0.620300\n"
     ]
    }
   ],
   "source": [
    "#Calculating accuracy for last-layer parameters\n",
    "model_conv, hist = train_model(model, criterion, optimizer,\n",
    "                         exp_lr_scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "Validation Loss: 0.0083 Acc: 0.0070\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "Validation Loss: 0.0119 Acc: 0.0060\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "Validation Loss: 0.0116 Acc: 0.0058\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "Validation Loss: 0.0091 Acc: 0.0075\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "Validation Loss: 0.0104 Acc: 0.0064\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "Validation Loss: 0.0105 Acc: 0.0058\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "Validation Loss: 0.0116 Acc: 0.0060\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "Validation Loss: 0.0103 Acc: 0.0059\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "Validation Loss: 0.0100 Acc: 0.0071\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "Validation Loss: 0.0089 Acc: 0.0069\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "Validation Loss: 0.0108 Acc: 0.0059\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "Validation Loss: 0.0108 Acc: 0.0066\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "Validation Loss: 0.0111 Acc: 0.0061\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "Validation Loss: 0.0117 Acc: 0.0057\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "Validation Loss: 0.0106 Acc: 0.0063\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "Validation Loss: 0.0113 Acc: 0.0060\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "Validation Loss: 0.0108 Acc: 0.0058\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "Validation Loss: 0.0102 Acc: 0.0066\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "Validation Loss: 0.0099 Acc: 0.0071\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "Validation Loss: 0.0110 Acc: 0.0058\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "Validation Loss: 0.0130 Acc: 0.0052\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "Validation Loss: 0.0094 Acc: 0.0068\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "Validation Loss: 0.0103 Acc: 0.0061\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "Validation Loss: 0.0111 Acc: 0.0060\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "Validation Loss: 0.0100 Acc: 0.0069\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "Validation Loss: 0.0103 Acc: 0.0061\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "Validation Loss: 0.0118 Acc: 0.0058\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "Validation Loss: 0.0095 Acc: 0.0064\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "Validation Loss: 0.0106 Acc: 0.0064\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "Validation Loss: 0.0111 Acc: 0.0063\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "Validation Loss: 0.0098 Acc: 0.0071\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "Validation Loss: 0.0106 Acc: 0.0066\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "Validation Loss: 0.0101 Acc: 0.0060\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "Validation Loss: 0.0114 Acc: 0.0062\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "Validation Loss: 0.0107 Acc: 0.0062\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "Validation Loss: 0.0104 Acc: 0.0063\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "Validation Loss: 0.0108 Acc: 0.0063\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "Validation Loss: 0.0108 Acc: 0.0062\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "Validation Loss: 0.0101 Acc: 0.0061\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "Validation Loss: 0.0115 Acc: 0.0062\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "Validation Loss: 0.0107 Acc: 0.0061\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "Validation Loss: 0.0132 Acc: 0.0059\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "Validation Loss: 0.0112 Acc: 0.0063\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "Validation Loss: 0.0110 Acc: 0.0061\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "Validation Loss: 0.0098 Acc: 0.0065\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "Validation Loss: 0.0118 Acc: 0.0055\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "Validation Loss: 0.0106 Acc: 0.0062\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "Validation Loss: 0.0130 Acc: 0.0056\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "Validation Loss: 0.0110 Acc: 0.0060\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "Validation Loss: 0.0117 Acc: 0.0060\n",
      "\n",
      "Training complete in 4m 38s\n",
      "Best val Acc: 0.007500\n"
     ]
    }
   ],
   "source": [
    "# Calculating accuracy for the entire pretained resnet18\n",
    "\n",
    "since = time.time()\n",
    "val_acc_history = []\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "    print('-' * 10)\n",
    "    for inputs, labels in dataloaders['val']:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "    # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    epoch_loss = running_loss / dataset_sizes['val']\n",
    "    epoch_acc = running_corrects.double() / dataset_sizes['val']\n",
    "    print(f'Validation Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "    print()\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen by looking at the accuracies of the above two models (one where only last layer parameters are updated and later one is resnet18(pretrained = True)). The accuracy for the pretrained model is much less as compared to the model where last layer parameters are updated. (0.624000 > 0.0075)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pyt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4cafaace53dbfa2f2f80725cf8b8a707efc1de97ef1c6af3883bc118682f6610"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
