{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "model = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "preprocess = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "processed_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=preprocess)\n",
    "class_names = processed_trainset.classes\n",
    "processed_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=preprocess)\n",
    "dataloaders = {'train' : [], 'val' : []}\n",
    "dataloaders['train'] = torch.utils.data.DataLoader(processed_trainset, batch_size=100,\n",
    "                                                    shuffle=True, num_workers=4, pin_memory=True)\n",
    "dataloaders['val'] = torch.utils.data.DataLoader(processed_testset, batch_size=100,\n",
    "                                                    shuffle=False, num_workers=4, pin_memory=True)\n",
    "dataset_sizes = {'train' : len(processed_trainset), 'val' : len(processed_testset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(512, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "dataset_sizes = {'train' : 50000 , 'val' : 10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.1938 Acc: 0.5886\n",
      "val Loss: 1.1682 Acc: 0.5919\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.1617 Acc: 0.5955\n",
      "val Loss: 1.1457 Acc: 0.6006\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.1464 Acc: 0.6014\n",
      "val Loss: 1.1302 Acc: 0.6030\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.1312 Acc: 0.6062\n",
      "val Loss: 1.1297 Acc: 0.6108\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.1298 Acc: 0.6067\n",
      "val Loss: 1.1252 Acc: 0.6070\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.1146 Acc: 0.6098\n",
      "val Loss: 1.1294 Acc: 0.6011\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.1154 Acc: 0.6117\n",
      "val Loss: 1.1248 Acc: 0.6053\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.1147 Acc: 0.6118\n",
      "val Loss: 1.1113 Acc: 0.6120\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.1172 Acc: 0.6097\n",
      "val Loss: 1.1133 Acc: 0.6113\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.1148 Acc: 0.6092\n",
      "val Loss: 1.1104 Acc: 0.6151\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 1.1168 Acc: 0.6094\n",
      "val Loss: 1.1068 Acc: 0.6077\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.1145 Acc: 0.6100\n",
      "val Loss: 1.0983 Acc: 0.6177\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.1087 Acc: 0.6125\n",
      "val Loss: 1.1068 Acc: 0.6134\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 1.1106 Acc: 0.6124\n",
      "val Loss: 1.1102 Acc: 0.6061\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 1.1165 Acc: 0.6102\n",
      "val Loss: 1.1165 Acc: 0.6098\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 1.1127 Acc: 0.6122\n",
      "val Loss: 1.1118 Acc: 0.6152\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 1.1120 Acc: 0.6111\n",
      "val Loss: 1.1082 Acc: 0.6082\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 1.1088 Acc: 0.6130\n",
      "val Loss: 1.1192 Acc: 0.6059\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 1.1147 Acc: 0.6125\n",
      "val Loss: 1.1082 Acc: 0.6158\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 1.1167 Acc: 0.6100\n",
      "val Loss: 1.1142 Acc: 0.6110\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 1.1094 Acc: 0.6129\n",
      "val Loss: 1.1093 Acc: 0.6149\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 1.1139 Acc: 0.6092\n",
      "val Loss: 1.1197 Acc: 0.6116\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 1.1125 Acc: 0.6123\n",
      "val Loss: 1.1218 Acc: 0.6093\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 1.1121 Acc: 0.6126\n",
      "val Loss: 1.1309 Acc: 0.6033\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 1.1176 Acc: 0.6105\n",
      "val Loss: 1.1080 Acc: 0.6188\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 1.1137 Acc: 0.6132\n",
      "val Loss: 1.1115 Acc: 0.6148\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 1.1141 Acc: 0.6093\n",
      "val Loss: 1.1246 Acc: 0.6064\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 1.1143 Acc: 0.6095\n",
      "val Loss: 1.1184 Acc: 0.6054\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 1.1185 Acc: 0.6064\n",
      "val Loss: 1.1088 Acc: 0.6139\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 1.1102 Acc: 0.6153\n",
      "val Loss: 1.1193 Acc: 0.6043\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 1.1150 Acc: 0.6112\n",
      "val Loss: 1.1205 Acc: 0.6061\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 1.1127 Acc: 0.6123\n",
      "val Loss: 1.0985 Acc: 0.6240\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 1.1116 Acc: 0.6122\n",
      "val Loss: 1.1231 Acc: 0.6057\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 1.1095 Acc: 0.6126\n",
      "val Loss: 1.1180 Acc: 0.6102\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 1.1126 Acc: 0.6111\n",
      "val Loss: 1.1062 Acc: 0.6128\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 1.1173 Acc: 0.6112\n",
      "val Loss: 1.1158 Acc: 0.6123\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 1.1145 Acc: 0.6091\n",
      "val Loss: 1.1201 Acc: 0.6126\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 1.1185 Acc: 0.6094\n",
      "val Loss: 1.1240 Acc: 0.6058\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 1.1121 Acc: 0.6125\n",
      "val Loss: 1.1075 Acc: 0.6127\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 1.1175 Acc: 0.6143\n",
      "val Loss: 1.1117 Acc: 0.6135\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 1.1135 Acc: 0.6110\n",
      "val Loss: 1.0956 Acc: 0.6160\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 1.1115 Acc: 0.6117\n",
      "val Loss: 1.1141 Acc: 0.6090\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 1.1108 Acc: 0.6121\n",
      "val Loss: 1.1167 Acc: 0.6086\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 1.1072 Acc: 0.6146\n",
      "val Loss: 1.1204 Acc: 0.6081\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 1.1088 Acc: 0.6134\n",
      "val Loss: 1.1082 Acc: 0.6070\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 1.1135 Acc: 0.6106\n",
      "val Loss: 1.1118 Acc: 0.6111\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 1.1141 Acc: 0.6122\n",
      "val Loss: 1.0984 Acc: 0.6176\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 1.1112 Acc: 0.6128\n",
      "val Loss: 1.1125 Acc: 0.6139\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 1.1088 Acc: 0.6143\n",
      "val Loss: 1.1114 Acc: 0.6119\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 1.1163 Acc: 0.6098\n",
      "val Loss: 1.1031 Acc: 0.6169\n",
      "\n",
      "Training complete in 28m 47s\n",
      "Best val Acc: 0.624000\n"
     ]
    }
   ],
   "source": [
    "#Calculating accuracy for last-layer parameters\n",
    "model_conv, hist = train_model(model, criterion, optimizer,\n",
    "                         exp_lr_scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "Validation Loss: 0.0083 Acc: 0.0070\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "Validation Loss: 0.0119 Acc: 0.0060\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "Validation Loss: 0.0116 Acc: 0.0058\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "Validation Loss: 0.0091 Acc: 0.0075\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "Validation Loss: 0.0104 Acc: 0.0064\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "Validation Loss: 0.0105 Acc: 0.0058\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "Validation Loss: 0.0116 Acc: 0.0060\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "Validation Loss: 0.0103 Acc: 0.0059\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "Validation Loss: 0.0100 Acc: 0.0071\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "Validation Loss: 0.0089 Acc: 0.0069\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "Validation Loss: 0.0108 Acc: 0.0059\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "Validation Loss: 0.0108 Acc: 0.0066\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "Validation Loss: 0.0111 Acc: 0.0061\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "Validation Loss: 0.0117 Acc: 0.0057\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "Validation Loss: 0.0106 Acc: 0.0063\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "Validation Loss: 0.0113 Acc: 0.0060\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "Validation Loss: 0.0108 Acc: 0.0058\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "Validation Loss: 0.0102 Acc: 0.0066\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "Validation Loss: 0.0099 Acc: 0.0071\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "Validation Loss: 0.0110 Acc: 0.0058\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "Validation Loss: 0.0130 Acc: 0.0052\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "Validation Loss: 0.0094 Acc: 0.0068\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "Validation Loss: 0.0103 Acc: 0.0061\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "Validation Loss: 0.0111 Acc: 0.0060\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "Validation Loss: 0.0100 Acc: 0.0069\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "Validation Loss: 0.0103 Acc: 0.0061\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "Validation Loss: 0.0118 Acc: 0.0058\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "Validation Loss: 0.0095 Acc: 0.0064\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "Validation Loss: 0.0106 Acc: 0.0064\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "Validation Loss: 0.0111 Acc: 0.0063\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "Validation Loss: 0.0098 Acc: 0.0071\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "Validation Loss: 0.0106 Acc: 0.0066\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "Validation Loss: 0.0101 Acc: 0.0060\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "Validation Loss: 0.0114 Acc: 0.0062\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "Validation Loss: 0.0107 Acc: 0.0062\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "Validation Loss: 0.0104 Acc: 0.0063\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "Validation Loss: 0.0108 Acc: 0.0063\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "Validation Loss: 0.0108 Acc: 0.0062\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "Validation Loss: 0.0101 Acc: 0.0061\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "Validation Loss: 0.0115 Acc: 0.0062\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "Validation Loss: 0.0107 Acc: 0.0061\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "Validation Loss: 0.0132 Acc: 0.0059\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "Validation Loss: 0.0112 Acc: 0.0063\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "Validation Loss: 0.0110 Acc: 0.0061\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "Validation Loss: 0.0098 Acc: 0.0065\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "Validation Loss: 0.0118 Acc: 0.0055\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "Validation Loss: 0.0106 Acc: 0.0062\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "Validation Loss: 0.0130 Acc: 0.0056\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "Validation Loss: 0.0110 Acc: 0.0060\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "Validation Loss: 0.0117 Acc: 0.0060\n",
      "\n",
      "Training complete in 4m 38s\n",
      "Best val Acc: 0.007500\n"
     ]
    }
   ],
   "source": [
    "# Calculating accuracy for the entire pretained resnet18\n",
    "\n",
    "since = time.time()\n",
    "val_acc_history = []\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "    print('-' * 10)\n",
    "    for inputs, labels in dataloaders['val']:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "    # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    epoch_loss = running_loss / dataset_sizes['val']\n",
    "    epoch_acc = running_corrects.double() / dataset_sizes['val']\n",
    "    print(f'Validation Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "    print()\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen by looking at the accuracies of the above two models (one where only last layer parameters are updated and later one is resnet18(pretrained = True)). The accuracy for the pretrained model is much less as compared to the model where last layer parameters are updated. (0.624000 > 0.0075)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pyt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4cafaace53dbfa2f2f80725cf8b8a707efc1de97ef1c6af3883bc118682f6610"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
